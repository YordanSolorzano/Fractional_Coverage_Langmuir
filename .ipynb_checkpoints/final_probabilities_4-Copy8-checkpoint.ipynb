{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df710d4a-d044-4400-be9a-3940b635b653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc30adb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d873b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6520d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a1f3f",
   "metadata": {},
   "source": [
    "## Implementacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dbbca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Standard library\n",
    "import os\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ASE (Atomic Simulation Environment)\n",
    "from ase.units import kB  # Boltzmann constant\n",
    "\n",
    "# Animations Library\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def probabilities(n_adatoms, E_bind, hexagonal, rhombile, triangular, \n",
    "                  C_nPh6, T_max, T_min, n_sites):\n",
    " \n",
    "    \"\"\"\n",
    "    Calculate the surface coverage when an adatom is inserted.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_adatoms : int\n",
    "        Number of adatoms.\n",
    "    E_bind : float\n",
    "        Binding energy of the system.\n",
    "    hexagonal : list of float\n",
    "        Adsorption energy of the hexagonal structure.\n",
    "    rhombile : list of float\n",
    "        Adsorption energy of the rhombile structure.\n",
    "    triangular : list of float\n",
    "        Adsorption energy of the triangular structure.\n",
    "    C_nPh6 : float\n",
    "        Concentration of gas molecules.\n",
    "    T_max : int\n",
    "        Maximum temperature [K].\n",
    "    T_min : int\n",
    "        Minimum temperature [K].\n",
    "    n_sites : int\n",
    "        Number of adsorption sites (e.g., 18x24 = 432).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Saves multiple CSV and PNG files with calculated data.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    E_bind_float = float(E_bind)\n",
    "    # Define a array Temperature \n",
    "    temperature = np.linspace(T_min, T_max, T_max - T_min + 1)\n",
    "    \n",
    "\n",
    "    kb_T = temperature*kB  # Energy [eV] equivalent to 100ºC , 25.3\n",
    "    \n",
    "    # Define the energy of isolated surface\n",
    "    isolated = 0\n",
    "    \n",
    "    # Calculate theta_Auad for array Temperature\n",
    "    theta_Auad = np.exp(E_bind_float / (kB * temperature)) / (1 + np.exp(E_bind_float / (kB * temperature)))\n",
    "\n",
    "    # Define a dicctionary initial with the columna Temperature to save probabilities\n",
    "    data = {'Temperatura': temperature}\n",
    "\n",
    "    # Define a dicctionary initia to save values of probabilities*coverage\n",
    "    data_pxc = {'Temperatura': temperature}\n",
    "\n",
    "    # Define the Absorption energy &  Kinetics Adsortion\n",
    "    K_ads = np.exp((4.311064999999871)/kb_T) \n",
    "    \n",
    "    \n",
    "    \n",
    "    ######## Calculations for surface without adatoms ######\n",
    "    \n",
    "    # Initialization of Probability with no adatom (adatom 0) \n",
    "    p_nad_0 = (1 - theta_Auad) ** n_sites\n",
    "\n",
    "    # Add the first column to diccitonary of probabilities 'data' which is adatom 0\n",
    "    data['P_Nad_0'] = p_nad_0\n",
    "\n",
    "    #  Arrhenius relation of kinetics \n",
    "    K_Ph6_0  = np.exp( (isolated)   /(kB * temperature))        # Isolated molecule\n",
    "    K_3Ph6_0 = np.exp(-(hexagonal[0] ) /(kB * temperature))     # Hexagonal\n",
    "    K_6Ph6_0 = np.exp(-(rhombile[0]  )   /(kB * temperature))   # Rhombile\n",
    "    K_9Ph6_0 = np.exp(-(triangular[0]) /(kB * temperature))     # Trinagular\n",
    "    \n",
    "    # Calculate Thetha for 0 adatoms\n",
    "    theta_clean_0 = 1 /(1 +   C_nPh6 * K_ads * (1 + K_3Ph6_0 + K_6Ph6_0 + K_9Ph6_0 ))\n",
    "\n",
    "\n",
    "    #Calculate the coverage of each structure in the surface  \n",
    "    theta_Ph6_0  = theta_clean_0 * C_nPh6   *  K_ads\n",
    "    theta_3Ph6_0 = theta_Ph6_0   * K_3Ph6_0\n",
    "    theta_6Ph6_0 = theta_Ph6_0   * K_6Ph6_0\n",
    "    theta_9Ph6_0 = theta_Ph6_0   * K_9Ph6_0\n",
    "    \n",
    "    # Define a dicctionary to save the probabilities*coverage of non adatoms juntionsç\n",
    "    \n",
    "    data_0 = {\n",
    "        \"Temperatur [K]\": temperature ,\n",
    "        f\"theta_3Ph6\":     p_nad_0  *  theta_3Ph6_0,\n",
    "        f\"theta_6Ph6\":     p_nad_0  *  theta_6Ph6_0,\n",
    "        f\"theta_9Ph6\":     p_nad_0  *  theta_9Ph6_0,\n",
    "        f\"theta_clean\":    p_nad_0  *  theta_clean_0,\n",
    "        f\"theta_isolated\": p_nad_0  *  theta_Ph6_0\n",
    "    }\n",
    "\n",
    "\n",
    "    # Create the data frame \n",
    "    probability_0 = pd.DataFrame(data_0)\n",
    "    \n",
    "    #Save data frame of coverage with non adatoms\n",
    "    probability_0.to_csv(f'./results/coverage_adatom_0_{E_bind}.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "\n",
    "    # fractional coverage which the sum of all networks structure\n",
    "    coverage_0 = probability_0['theta_3Ph6'] + probability_0['theta_6Ph6'] + probability_0['theta_9Ph6'] + probability_0['theta_clean'] + probability_0['theta_isolated']\n",
    "\n",
    "    ########### Finish calculations with no adatoms   ##############\n",
    "    \n",
    "    ###### Initializations of calculations of coverages from 1 to n adatoms  #######\n",
    "    \n",
    "    \n",
    "    # Define the initialization variable with coverage 0 \n",
    "    coverage_acum = coverage_0.copy()  # sum acummulative into the for loop\n",
    "    coverage_acum_2 = coverage_0.copy()  # sum acummulative into the for loop\n",
    "    # Define a dicctionary for fractional coverage acummulative \n",
    "    fractional_ac_coverage = {'Temperatura': temperature,\n",
    "                          'coverage_0':  coverage_0}\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Plotting \n",
    "    # Configuración estética sin cuadrícula de fondo y con bordes de ticks\n",
    "    sns.set_style(\"ticks\")  \n",
    "    # Forzar uso de Times New Roman\n",
    "    plt.rcParams['font.family'] = 'serif'  # Usa 'serif' como alternativa en caso de que Times New Roman no esté disponible\n",
    "    plt.rcParams['font.serif'] = 'Times New Roman'  # Esto forzará a usar Times New Roman si está instalado\n",
    "    plt.rcParams['font.size'] = 12  # Tamaño de fuente 12\n",
    "    # Graficar las líneas\n",
    "    plt.plot(temperature, coverage_0, color='black', linewidth=0.3)\n",
    "    # Rellenar el área entre la curva más baja y el eje inferior (y=0)\n",
    "    plt.fill_between(temperature, 0, coverage_0, color='cyan', alpha=0.8, label='No adatom')\n",
    "    \n",
    "    \n",
    "    # Loop for to adding values into dicctionaries \n",
    "    for i in range(1, n_adatoms + 1):\n",
    "        \n",
    "        # Calculate using a recursive functions the probabilities of n adatoms\n",
    "        p_nad_i = (1 - sum(data['P_Nad_' + str(j)] for j in range(i))) * (1 - theta_Auad) ** (n_sites - i)\n",
    "        \n",
    "        # Save the  values of probabilities into a dicctionary\n",
    "        data['P_Nad_' + str(i)] = p_nad_i\n",
    "\n",
    "        #Arrhenius relation according the energies i of the array defined\n",
    "    \n",
    "        K_Ph6  = np.exp( (isolated)   /(kB * temperature))     # Isolated molecule\n",
    "        K_3Ph6 = np.exp(-(hexagonal[i] ) /(kB * temperature))     # Hexagonal\n",
    "        K_6Ph6 = np.exp(-(rhombile[i]  )   /(kB * temperature))  # Rhombile\n",
    "        K_9Ph6 = np.exp(-(triangular[i]) /(kB * temperature))  # Trinagular\n",
    "\n",
    "\n",
    "        # Calculate Thetha \n",
    "        theta_clean = 1 /(1 +   C_nPh6 * K_ads * (1 + K_3Ph6 + K_6Ph6 + K_9Ph6 ))\n",
    "\n",
    "\n",
    "        # Calculate the coverage of each structure in the surface \n",
    "        theta_Ph6  = theta_clean * C_nPh6   *  K_ads\n",
    "        theta_3Ph6 = theta_Ph6   * K_3Ph6\n",
    "        theta_6Ph6 = theta_Ph6   * K_6Ph6\n",
    "        theta_9Ph6 = theta_Ph6   * K_9Ph6\n",
    "\n",
    "        # Define a dicctionary to save the values of probabliites* coverage of n adatoms\n",
    "        data_pxc = {\n",
    "            \"Temperatur [K]\": temperature ,\n",
    "            f\"theta_3Ph6\":     p_nad_i  *  theta_3Ph6,\n",
    "            f\"theta_6Ph6\":     p_nad_i  *  theta_6Ph6,\n",
    "            f\"theta_9Ph6\":     p_nad_i  *  theta_9Ph6,\n",
    "            f\"theta_clean\":    p_nad_i  *  theta_clean,\n",
    "            f\"theta_isolated\": p_nad_i  *  theta_Ph6}\n",
    "\n",
    "\n",
    "        # Created the data frame of the coverage*probabilities of n adatoms\n",
    "        probability = pd.DataFrame(data_pxc)\n",
    "\n",
    "        #Save data frame \n",
    "        probability.to_csv(f'./results/coverage_{i}_adatom__{E_bind}.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "        # Define the coverage of i adatoms which is the sum total of the networks structural\n",
    "        coverage = probability['theta_3Ph6'] + probability['theta_6Ph6'] + probability['theta_9Ph6'] + probability['theta_clean'] + probability['theta_isolated']\n",
    "\n",
    "        # Sumar cobertura actual a la acumulada\n",
    "        coverage_acum += coverage.copy()\n",
    "        \n",
    "        # Sum accumalative of n adatoms coverage*probabilities\n",
    "        fractional_ac_coverage['coverage_' + str(i)] = coverage_acum.copy()\n",
    "        \n",
    "        # Graficar las líneas\n",
    "        plt.plot(temperature, coverage_acum.copy(), color='black', linewidth=0.3)\n",
    "        \n",
    "        # Rellenar el área entre las curvas con diferentes colores\n",
    "        plt.fill_between(temperature,coverage_acum_2, coverage_acum.copy(), alpha=0.8, label=f'{i} adatom')\n",
    "        \n",
    "        coverage_acum_2+= coverage.copy()\n",
    "        \n",
    "    ###### Calculations the other posible structures which are unstable #######\n",
    "    # Calcular p_nad_more which is the non defined strucutres \n",
    "    p_nad_more = 1 - sum(data['P_Nad_' + str(j)] for j in range(n_adatoms + 1))\n",
    "    \n",
    "    # Save the values of p_nad_more on dicctionary of probabilities*coverage\n",
    "    data['P_Nad_more'] = p_nad_more\n",
    "\n",
    "    # Define a new dictionary of more n adatoms\n",
    "    \n",
    "    data_pxc_more = {\n",
    "        \"Temperatur [K]\": temperature ,\n",
    "        f\"theta_3Ph6\":     p_nad_more  *  theta_3Ph6,\n",
    "        f\"theta_6Ph6\":     p_nad_more  *  theta_6Ph6,\n",
    "        f\"theta_9Ph6\":     p_nad_more  *  theta_9Ph6,\n",
    "        f\"theta_clean\":    p_nad_more  *  theta_clean,\n",
    "        f\"theta_isolated\": p_nad_more  *  theta_Ph6}\n",
    "\n",
    "\n",
    "\n",
    "    # Created the data frame \n",
    "    probability_more = pd.DataFrame(data_pxc_more)\n",
    "    \n",
    "    #Save data frame \n",
    "    probability_more.to_csv(f'./results/coverage_adatom_more_{E_bind}.dat', sep= \" \", index=False,header=False)\n",
    "    \n",
    "    # define a sum of all structure difined \n",
    "    coverage_more = probability_more['theta_3Ph6'] + probability_more['theta_6Ph6'] + probability_more['theta_9Ph6'] + probability_more['theta_clean'] + probability_more['theta_isolated']\n",
    "\n",
    "    # Update the accumulative variable to sum coverge more\n",
    "    coverage_acum += coverage_more\n",
    "    \n",
    "    plt.plot(temperature, coverage_acum, color='black', linewidth=0.3)\n",
    "    plt.fill_between(temperature, coverage_acum_2, 1 , color='black', alpha=0.8,  label='more adatom')\n",
    " \n",
    "    # Add a new colummn  into the dicctionary correspont to more n adatoms\n",
    "    fractional_ac_coverage['coverage_more'] = coverage_acum.copy()\n",
    "\n",
    "    # Created the data frame \n",
    "    fractional_ac_coverage_set = pd.DataFrame(fractional_ac_coverage)\n",
    "\n",
    "    #Save data frame \n",
    "    fractional_ac_coverage_set.to_csv(f'./results/fractional_coverage_saved_{E_bind}.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "    # Ajustar límites para asegurar visibilidad completa\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlim(200, 700)\n",
    "\n",
    "    # Mejorar la leyenda\n",
    "    legend = plt.legend(frameon=True)\n",
    "    for text in legend.get_texts():\n",
    "        plt.setp(text, color='black')  # Color de texto en negro para mejor visibilidad\n",
    "    # Borde negro en la caja de leyenda\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_color('white')  # Color de fondo blanco\n",
    "    frame.set_edgecolor('black')  # Color del borde de la caja de leyenda\n",
    "\n",
    "    # Bordes negros en el gráfico\n",
    "    plt.gca().spines['top'].set_color('black')\n",
    "    plt.gca().spines['right'].set_color('black')\n",
    "    plt.gca().spines['bottom'].set_color('black')\n",
    "    plt.gca().spines['left'].set_color('black')\n",
    "    \n",
    "    \n",
    "    # Títulos y etiquetas de los ejes en Times New Roman\n",
    "    plt.title(rf'Coverage of Network Formation on Au(111) with E_bind = {E_bind} [eV/mol]')\n",
    "    plt.xlabel('Temperatura [K]', fontsize=12, fontname='Times New Roman')\n",
    "    plt.ylabel('Fractional Coverage [u.a.]', fontsize=12, fontname='Times New Roman')\n",
    "\n",
    "    plt.savefig(f'./results/network_formation_{E_bind}.png', dpi=300, bbox_inches='tight')\n",
    "    # Mostrar gráfico\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "def coverage_fractional_E_bind(n_adatoms, hexagonal, rhombile, triangular, C_nPh6, T_max, T_min, n_sites, e_bin_min, e_bin_max):\n",
    "    \n",
    "    # Creating a folder to save the results\n",
    "    try:\n",
    "        os.makedirs('./results', exist_ok=True)\n",
    "        print(f\"Directorio '{'./results'}' creado o ya existente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al crear el directorio '{'./results'}': {e}\")\n",
    "    \n",
    "    # Ensure it's an integer\n",
    "    num_points = int((abs(e_bin_max - e_bin_min) + 0.01) * 100)\n",
    "    \n",
    "    # Create an array for binding energies\n",
    "    energies = np.linspace(e_bin_min, e_bin_max, num_points)\n",
    "\n",
    "    # Give a format of string  to created a geit animation \n",
    "    energies_formatted = [f\"{energy:.2f}\" for energy in energies]\n",
    "\n",
    "\n",
    "    # Loop for each e_binding in energies_formated \n",
    "    for e_binding in energies_formatted:\n",
    "        probabilities(n_adatoms,\n",
    "                        e_binding, \n",
    "                        hexagonal,\n",
    "                        rhombile, \n",
    "                        triangular,\n",
    "                        C_nPh6,\n",
    "                        T_max,\n",
    "                        T_min,\n",
    "                        n_sites)\n",
    "    \n",
    "    # Ruta a las imágenes\n",
    "    images_in = glob.glob(\"./results/network_formation_****.png\")\n",
    "    \n",
    "    # Cargar las imágenes\n",
    "    images = [Image.open(img) for img in sorted(images_in)]\n",
    "    \n",
    "    # Crear el GIF\n",
    "    gif_image_out = f\"./results/animation_{n_adatoms}_adatoms.gif\"\n",
    "    images[0].save(gif_image_out, save_all=True, append_images=images[1:], duration=400, loop=0)\n",
    "    \n",
    "    print(f\"GIF guardado como {gif_image_out}\")\n",
    "\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "604d62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values of the input funcion\n",
    "\n",
    "n_adatoms=6\n",
    "E_bind=-0.30\n",
    "hexagonal=[0.182, -0.047, -0.251, -0.251, -0.251, -0.251, -0.251]\n",
    "rhombile=[0.317, 0.209, 0.106, -0.006, -0.142, -0.202, -0.146]\n",
    "triangular=[0.547, 0.547, 0.547, 0.138, 0.138, 0.138, 0.138]\n",
    "C_nPh6=1e-4\n",
    "T_max=700\n",
    "T_min=200\n",
    "n_sites=18*24\n",
    "\n",
    "e_bin_min=0\n",
    "e_bin_max=-0.67\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "999fddc7-bd82-4200-91ed-adf4554de6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio './results' creado o ya existente.\n",
      "GIF guardado como ./results/animation_6_adatoms.gif\n"
     ]
    }
   ],
   "source": [
    "coverage_fractional_E_bind(n_adatoms, hexagonal, rhombile, triangular, C_nPh6, T_max, T_min, n_sites, e_bin_min, e_bin_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cc9076",
   "metadata": {},
   "source": [
    "# VERIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0505b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import coverage_{i} dataframe \n",
    "coverage_0 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_0.dat', sep= \" \", header=None)\n",
    "coverage_1 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_1.dat', sep= \" \", header=None)\n",
    "coverage_2 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_2.dat', sep= \" \", header=None)\n",
    "coverage_3 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_3.dat', sep= \" \", header=None)\n",
    "coverage_4 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_4.dat', sep= \" \", header=None)\n",
    "coverage_5 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_5.dat', sep= \" \", header=None)\n",
    "coverage_6 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_6.dat', sep= \" \", header=None)\n",
    "coverage_more = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_more.dat', sep= \" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2933d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de DataFrames\n",
    "dataframes = [coverage_0, coverage_1, coverage_2, coverage_3,coverage_4, coverage_5 , coverage_6, coverage_more]\n",
    "\n",
    "# Excluir la primera fila y la primera columna de cada DataFrame\n",
    "excluded_dfs = [df.iloc[:, 1:] for df in dataframes]\n",
    "\n",
    "# Sumar todas las columnas de los DataFrames excluidos\n",
    "sum_columns_general = sum(df.sum(axis=1) for df in excluded_dfs)\n",
    "\n",
    "# Crear un nuevo DataFrame con la suma total\n",
    "result_df = pd.DataFrame(sum_columns_general, columns=['Total Sum'])\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(\"Suma total de todas las columnas (excluye la primera columna):\\n\", result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab33abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c6328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

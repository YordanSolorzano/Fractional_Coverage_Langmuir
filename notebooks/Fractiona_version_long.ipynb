{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e98edc-0971-47de-b447-089b6ae28595",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df710d4a-d044-4400-be9a-3940b635b653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc30adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from ase.units import kB  #Boltzman constants \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d873b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values of the input funcion\n",
    "\n",
    "n_adatoms=6\n",
    "E_bind=-0.30\n",
    "hexagonal=[0.182, -0.047, -0.251, -0.251, -0.251, -0.251, -0.251]\n",
    "rhombile=[0.317, 0.209, 0.106, -0.006, -0.142, -0.202, -0.146]\n",
    "triangular=[0.547, 0.547, 0.547, 0.138, 0.138, 0.138, 0.138]\n",
    "C_nPh6=1e-4\n",
    "T_max=700\n",
    "T_min=200\n",
    "n_sites=18*24\n",
    "isolated=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6520d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9ab55",
   "metadata": {},
   "source": [
    "# Calculo mejorado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01fdd7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "isolated = 0\n",
    "# Calcular theta_Auad para cada temperatura\n",
    "theta_Auad = np.exp(E_bind / (kB * Temperature)) / (1 + np.exp(E_bind / (kB * Temperature)))\n",
    "\n",
    "# Crear un diccionario inicial con la columna 'Temperatura'\n",
    "data = {'Temperatura': Temperature}\n",
    "\n",
    "# Crear un diccionario de probabilidad per coverage\n",
    "data_pxc = {'Temperatura': Temperature}\n",
    "\n",
    "#Absorption energies\n",
    "K_ads = np.exp((4.311064999999871)/kb_T) \n",
    "\n",
    "# Inicializar el primer valor P_Nad_0 fuera del bucle\n",
    "P_Nad_0 = (1 - theta_Auad) ** n_sites\n",
    "\n",
    "# Agregar la primera columna 'P_Nad_0' al diccionario\n",
    "data['P_Nad_0'] = P_Nad_0\n",
    "\n",
    "#Arrhenius relation\n",
    "K_Ph6_0  = np.exp( (isolated)   /(kB * Temperature))        # Isolated molecule\n",
    "K_3Ph6_0 = np.exp(-(hexagonal[0] ) /(kB * Temperature))     # Hexagonal\n",
    "K_6Ph6_0 = np.exp(-(rhombile[0]  )   /(kB * Temperature))   # Rhombile\n",
    "K_9Ph6_0 = np.exp(-(triangular[0]) /(kB * Temperature))     # Trinagular\n",
    "\n",
    "# Calculate Thetha \n",
    "theta_clean_0 = 1 /(1 +   C_nPh6 * K_ads * (1 + K_3Ph6_0 + K_6Ph6_0 + K_9Ph6_0 ))\n",
    "\n",
    "\n",
    "#Calculate the coverage of each structure in the surface \n",
    "theta_Ph6_0  = theta_clean_0 * C_nPh6   *  K_ads\n",
    "theta_3Ph6_0 = theta_Ph6_0   * K_3Ph6_0\n",
    "theta_6Ph6_0 = theta_Ph6_0   * K_6Ph6_0\n",
    "theta_9Ph6_0 = theta_Ph6_0   * K_9Ph6_0\n",
    "\n",
    "data_0 = {\n",
    "    \"Temperatur [K]\": Temperature ,\n",
    "    f\"theta_3Ph6\":     P_Nad_0  *  theta_3Ph6_0,\n",
    "    f\"theta_6Ph6\":     P_Nad_0  *  theta_6Ph6_0,\n",
    "    f\"theta_9Ph6\":     P_Nad_0  *  theta_9Ph6_0,\n",
    "    f\"theta_clean\":    P_Nad_0  *  theta_clean_0,\n",
    "    f\"theta_isolated\": P_Nad_0  *  theta_Ph6_0}\n",
    "\n",
    "\n",
    "# Created the data frame \n",
    "probability_0 = pd.DataFrame(data_0)\n",
    "#Save data frame \n",
    "probability_0.to_csv(f'/home/yor/Thesis/prueba/coverage_adatom_0.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "\n",
    "# fractional coverage \n",
    "coverage_0 = probability_0['theta_3Ph6'] + probability_0['theta_6Ph6'] + probability_0['theta_9Ph6'] + probability_0['theta_clean'] + probability_0['theta_isolated']\n",
    "\n",
    "\n",
    "# Inicializar cobertura acumulada con la primera cobertura (coverage_0)\n",
    "coverage_acum = coverage_0.copy()  # Variable para ir sumando acumulativamente\n",
    "\n",
    "# Define a dicctionary for fractional coverage acummulate \n",
    "\n",
    "fractional_ac_coverage = {'Temperatura': Temperature,\n",
    "                      'coverage_0':  coverage_0}\n",
    "\n",
    "\n",
    "# Rellenar el diccionario iterando para los siguientes P_Nad\n",
    "for i in range(1, n_adatoms + 1):\n",
    "    \n",
    "    P_Nad_i = (1 - sum(data['P_Nad_' + str(j)] for j in range(i))) * (1 - theta_Auad) ** (n_sites - i)\n",
    "    data['P_Nad_' + str(i)] = P_Nad_i\n",
    "    \n",
    "    #Arrhenius relation\n",
    "    K_Ph6  = np.exp( (isolated)   /(kB * Temperature))     # Isolated molecule\n",
    "    K_3Ph6 = np.exp(-(hexagonal[i] ) /(kB * Temperature))     # Hexagonal\n",
    "    K_6Ph6 = np.exp(-(rhombile[i]  )   /(kB * Temperature))  # Rhombile\n",
    "    K_9Ph6 = np.exp(-(triangular[i]) /(kB * Temperature))  # Trinagular\n",
    "    \n",
    "    \n",
    "    # Calculate Thetha \n",
    "    theta_clean = 1 /(1 +   C_nPh6 * K_ads * (1 + K_3Ph6 + K_6Ph6 + K_9Ph6 ))\n",
    "\n",
    "    \n",
    "    #Calculate the coverage of each structure in the surface \n",
    "    theta_Ph6  = theta_clean * C_nPh6   *  K_ads\n",
    "    theta_3Ph6 = theta_Ph6   * K_3Ph6\n",
    "    theta_6Ph6 = theta_Ph6   * K_6Ph6\n",
    "    theta_9Ph6 = theta_Ph6   * K_9Ph6\n",
    "    \n",
    "    #theta_Auad = np.exp(E_bind / (kB * T)) /(1 - np.exp(E_bind / (kB * T)))\n",
    "    \n",
    "\n",
    "    \n",
    "    data_pxc = {\n",
    "        \"Temperatur [K]\": Temperature ,\n",
    "        f\"theta_3Ph6\":     P_Nad_i  *  theta_3Ph6,\n",
    "        f\"theta_6Ph6\":     P_Nad_i  *  theta_6Ph6,\n",
    "        f\"theta_9Ph6\":     P_Nad_i  *  theta_9Ph6,\n",
    "        f\"theta_clean\":    P_Nad_i  *  theta_clean,\n",
    "        f\"theta_isolated\": P_Nad_i  *  theta_Ph6}\n",
    "\n",
    "    \n",
    "    # Created the data frame \n",
    "    probability = pd.DataFrame(data_pxc)\n",
    "    \n",
    "    #Save data frame \n",
    "    probability.to_csv(f'/home/yor/Thesis/prueba/coverage_adatom_{i}.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "    # Define the coverage of i adatoms which is the sum total of the networks structural\n",
    "    coverage = probability['theta_3Ph6'] + probability['theta_6Ph6'] + probability['theta_9Ph6'] + probability['theta_clean'] + probability['theta_isolated']\n",
    "    \n",
    "    #fractional_coverage['coverage_' + str(i)] = coverage\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    # Sumar cobertura actual a la acumulada\n",
    "    coverage_acum += coverage.copy()\n",
    "    \n",
    "    fractional_ac_coverage['coverage_' + str(i)] = coverage_acum.copy()\n",
    "\n",
    "    \n",
    "# Calcular P_Nad_more fuera del bucle (lo que resta para que la suma de probabilidades sea 1)\n",
    "P_Nad_more = 1 - sum(data['P_Nad_' + str(j)] for j in range(n_adatoms + 1))\n",
    "data['P_Nad_more'] = P_Nad_more\n",
    "\n",
    "data_pxc_more = {\n",
    "    \"Temperatur [K]\": Temperature ,\n",
    "    f\"theta_3Ph6\":     P_Nad_more  *  theta_3Ph6,\n",
    "    f\"theta_6Ph6\":     P_Nad_more  *  theta_6Ph6,\n",
    "    f\"theta_9Ph6\":     P_Nad_more  *  theta_9Ph6,\n",
    "    f\"theta_clean\":    P_Nad_more  *  theta_clean,\n",
    "    f\"theta_isolated\": P_Nad_more  *  theta_Ph6}\n",
    "\n",
    "\n",
    "\n",
    "# Created the data frame \n",
    "probability_more = pd.DataFrame(data_pxc_more)\n",
    "coverage_more = probability_more['theta_3Ph6'] + probability_more['theta_6Ph6'] + probability_more['theta_9Ph6'] + probability_more['theta_clean'] + probability_more['theta_isolated']\n",
    "\n",
    "\n",
    "#Save data frame \n",
    "probability_more.to_csv(f'/home/yor/Thesis/prueba/coverage_adatom_more.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "# Convertir el diccionario en DataFrame\n",
    "#df = pd.DataFrame(data)\n",
    "\n",
    "# Guardar en archivo CSV_\n",
    "#df.to_csv('/home/yor/Thesis/prueba/probabilities_set.csv', index=False, header=False)\n",
    "\n",
    "\n",
    "coverage_acum += coverage_more\n",
    "\n",
    "\n",
    "fractional_ac_coverage['coverage_more'] = coverage_acum.copy()\n",
    "\n",
    "# Created the data frame \n",
    "fractional_ac_coverage_set = pd.DataFrame(fractional_ac_coverage)\n",
    "\n",
    "#Save data frame \n",
    "fractional_ac_coverage_set.to_csv(f'/home/yor/Thesis/prueba/fractional_coverage_saved.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61617779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities(\n",
    "                    n_adatoms,\n",
    "                    E_bind, \n",
    "                    hexagonal,\n",
    "                    rhombile, \n",
    "                    triangular,\n",
    "                    C_nPh6,\n",
    "                    T_max,\n",
    "                    T_min,\n",
    "                    n_sites): \n",
    "    \"\"\"\n",
    "    This function calculates the coverage on the surface when an adatom is inserted.\n",
    "\n",
    "    Inputs -------->\n",
    "    \n",
    "            n_adatoms  -- number of adatoms\n",
    "            C_Ph6      -- concentration of gas \n",
    "            T_max      -- maximum temperature\n",
    "            T_min      -- minimum temperature\n",
    "            n_sites    -- dimension of unit cell (ex. 18x24 = 432)\n",
    "            isolated   -- energy of isolated structure (It is zero by definition)\n",
    "            hexagonal  -- energy of adsorption of hexagonal structure\n",
    "            rhombile   -- energy adsorption of rhombile structure \n",
    "            triangular -- energy adsorption of triangular structure \n",
    "\n",
    "    Outputs -------->\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Temperature = np.linspace(T_min, T_max, T_max-T_min+1)\n",
    "\n",
    "    kb_T = Temperature*kB  # Energy [eV] equivalent to 100ºC , 25.3\n",
    "    \n",
    "    # Define the energy of isolated surface\n",
    "    isolated = 0\n",
    "    \n",
    "    # Calculate theta_Auad for array Temperature\n",
    "    theta_Auad = np.exp(E_bind / (kB * Temperature)) / (1 + np.exp(E_bind / (kB * Temperature)))\n",
    "\n",
    "    # Define a dicctionary initial with the columna Temperature to save probabilities\n",
    "    data = {'Temperatura': Temperature}\n",
    "\n",
    "    # Define a dicctionary initia to save values of probabilities*coverage\n",
    "    data_pxc = {'Temperatura': Temperature}\n",
    "\n",
    "    # Define the Absorption energy &  Kinetics Adsortion\n",
    "    K_ads = np.exp((4.311064999999871)/kb_T) \n",
    "    \n",
    "    \n",
    "    \n",
    "    ######## Calculations for No adatoms ######\n",
    "    \n",
    "    # Initialization of Probability with no adatom (adatom 0) \n",
    "    P_Nad_0 = (1 - theta_Auad) ** n_sites\n",
    "\n",
    "    # Add the first column to diccitonary of probabilities 'data' which is adatom 0\n",
    "    data['P_Nad_0'] = P_Nad_0\n",
    "\n",
    "    #  Arrhenius relation of kinetics \n",
    "    K_Ph6_0  = np.exp( (isolated)   /(kB * Temperature))        # Isolated molecule\n",
    "    K_3Ph6_0 = np.exp(-(hexagonal[0] ) /(kB * Temperature))     # Hexagonal\n",
    "    K_6Ph6_0 = np.exp(-(rhombile[0]  )   /(kB * Temperature))   # Rhombile\n",
    "    K_9Ph6_0 = np.exp(-(triangular[0]) /(kB * Temperature))     # Trinagular\n",
    "    \n",
    "    # Calculate Thetha for 0 adatoms\n",
    "    theta_clean_0 = 1 /(1 +   C_nPh6 * K_ads * (1 + K_3Ph6_0 + K_6Ph6_0 + K_9Ph6_0 ))\n",
    "\n",
    "\n",
    "    #Calculate the coverage of each structure in the surface  \n",
    "    theta_Ph6_0  = theta_clean_0 * C_nPh6   *  K_ads\n",
    "    theta_3Ph6_0 = theta_Ph6_0   * K_3Ph6_0\n",
    "    theta_6Ph6_0 = theta_Ph6_0   * K_6Ph6_0\n",
    "    theta_9Ph6_0 = theta_Ph6_0   * K_9Ph6_0\n",
    "    \n",
    "    # Define a dicctionary to save the probabilities*coverage of non adatoms juntionsç\n",
    "    \n",
    "    data_0 = {\n",
    "        \"Temperatur [K]\": Temperature ,\n",
    "        f\"theta_3Ph6\":     P_Nad_0  *  theta_3Ph6_0,\n",
    "        f\"theta_6Ph6\":     P_Nad_0  *  theta_6Ph6_0,\n",
    "        f\"theta_9Ph6\":     P_Nad_0  *  theta_9Ph6_0,\n",
    "        f\"theta_clean\":    P_Nad_0  *  theta_clean_0,\n",
    "        f\"theta_isolated\": P_Nad_0  *  theta_Ph6_0\n",
    "    }\n",
    "\n",
    "\n",
    "    # Create the data frame \n",
    "    probability_0 = pd.DataFrame(data_0)\n",
    "    \n",
    "    #Save data frame of coverage with non adatoms\n",
    "    probability_0.to_csv(f'/home/yor/Thesis/prueba/coverage_adatom_0.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "\n",
    "    # fractional coverage which the sum of all networks structure\n",
    "    coverage_0 = probability_0['theta_3Ph6'] + probability_0['theta_6Ph6'] + probability_0['theta_9Ph6'] + probability_0['theta_clean'] + probability_0['theta_isolated']\n",
    "\n",
    "    ########### Finish calculations with no adatoms   ##############\n",
    "    \n",
    "    ###### Initializations of calculations of coverages from 1 to n adatoms  #######\n",
    "    \n",
    "    \n",
    "    # Define the initialization variable with coverage 0 \n",
    "    coverage_acum = coverage_0.copy()  # sum acummulative into the for loop\n",
    "\n",
    "    # Define a dicctionary for fractional coverage acummulative \n",
    "    fractional_ac_coverage = {'Temperatura': Temperature,\n",
    "                          'coverage_0':  coverage_0}\n",
    "\n",
    "    # Loop for to adding values into dicctionaries \n",
    "    for i in range(1, n_adatoms + 1):\n",
    "        \n",
    "        # Calculate using a recursive functions the probabilities of n adatoms\n",
    "        P_Nad_i = (1 - sum(data['P_Nad_' + str(j)] for j in range(i))) * (1 - theta_Auad) ** (n_sites - i)\n",
    "        \n",
    "        # Save the  values of probabilities into a dicctionary\n",
    "        data['P_Nad_' + str(i)] = P_Nad_i\n",
    "\n",
    "        #Arrhenius relation according the energies i of the array defined\n",
    "    \n",
    "        K_Ph6  = np.exp( (isolated)   /(kB * Temperature))     # Isolated molecule\n",
    "        K_3Ph6 = np.exp(-(hexagonal[i] ) /(kB * Temperature))     # Hexagonal\n",
    "        K_6Ph6 = np.exp(-(rhombile[i]  )   /(kB * Temperature))  # Rhombile\n",
    "        K_9Ph6 = np.exp(-(triangular[i]) /(kB * Temperature))  # Trinagular\n",
    "\n",
    "\n",
    "        # Calculate Thetha \n",
    "        theta_clean = 1 /(1 +   C_nPh6 * K_ads * (1 + K_3Ph6 + K_6Ph6 + K_9Ph6 ))\n",
    "\n",
    "\n",
    "        # Calculate the coverage of each structure in the surface \n",
    "        theta_Ph6  = theta_clean * C_nPh6   *  K_ads\n",
    "        theta_3Ph6 = theta_Ph6   * K_3Ph6\n",
    "        theta_6Ph6 = theta_Ph6   * K_6Ph6\n",
    "        theta_9Ph6 = theta_Ph6   * K_9Ph6\n",
    "\n",
    "        # Define a dicctionary to save the values of probabliites* coverage of n adatoms\n",
    "        data_pxc = {\n",
    "            \"Temperatur [K]\": Temperature ,\n",
    "            f\"theta_3Ph6\":     P_Nad_i  *  theta_3Ph6,\n",
    "            f\"theta_6Ph6\":     P_Nad_i  *  theta_6Ph6,\n",
    "            f\"theta_9Ph6\":     P_Nad_i  *  theta_9Ph6,\n",
    "            f\"theta_clean\":    P_Nad_i  *  theta_clean,\n",
    "            f\"theta_isolated\": P_Nad_i  *  theta_Ph6}\n",
    "\n",
    "\n",
    "        # Created the data frame of the coverage*probabilities of n adatoms\n",
    "        probability = pd.DataFrame(data_pxc)\n",
    "\n",
    "        #Save data frame \n",
    "        probability.to_csv(f'/home/yor/Thesis/prueba/coverage_adatom_{i}.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "        # Define the coverage of i adatoms which is the sum total of the networks structural\n",
    "        coverage = probability['theta_3Ph6'] + probability['theta_6Ph6'] + probability['theta_9Ph6'] + probability['theta_clean'] + probability['theta_isolated']\n",
    "\n",
    "        # Sumar cobertura actual a la acumulada\n",
    "        coverage_acum += coverage.copy()\n",
    "        \n",
    "        # Sum accumalative of n adatoms coverage*probabilities\n",
    "        fractional_ac_coverage['coverage_' + str(i)] = coverage_acum.copy()\n",
    "        \n",
    "    ###### Calculations the other posible structures which are unstable #######\n",
    "    # Calcular P_Nad_more which is the non defined strucutres \n",
    "    P_Nad_more = 1 - sum(data['P_Nad_' + str(j)] for j in range(n_adatoms + 1))\n",
    "    \n",
    "    # Save the values of P_Nad_more on dicctionary of probabilities*coverage\n",
    "    data['P_Nad_more'] = P_Nad_more\n",
    "\n",
    "    # Define a new dictionary of more n adatoms\n",
    "    \n",
    "    data_pxc_more = {\n",
    "        \"Temperatur [K]\": Temperature ,\n",
    "        f\"theta_3Ph6\":     P_Nad_more  *  theta_3Ph6,\n",
    "        f\"theta_6Ph6\":     P_Nad_more  *  theta_6Ph6,\n",
    "        f\"theta_9Ph6\":     P_Nad_more  *  theta_9Ph6,\n",
    "        f\"theta_clean\":    P_Nad_more  *  theta_clean,\n",
    "        f\"theta_isolated\": P_Nad_more  *  theta_Ph6}\n",
    "\n",
    "\n",
    "\n",
    "    # Created the data frame \n",
    "    probability_more = pd.DataFrame(data_pxc_more)\n",
    "    \n",
    "    #Save data frame \n",
    "    probability_more.to_csv(f'/home/yor/Thesis/prueba/coverage_adatom_more.dat', sep= \" \", index=False,header=False)\n",
    "    \n",
    "    # define a sum of all structure difined \n",
    "    coverage_more = probability_more['theta_3Ph6'] + probability_more['theta_6Ph6'] + probability_more['theta_9Ph6'] + probability_more['theta_clean'] + probability_more['theta_isolated']\n",
    "\n",
    "\n",
    "\n",
    "    # Convertir el diccionario en DataFrame\n",
    "    #df = pd.DataFrame(data)\n",
    "\n",
    "    # Guardar en archivo CSV_\n",
    "    #df.to_csv('/home/yor/Thesis/prueba/probabilities_set.csv', index=False, header=False)\n",
    "\n",
    "    # Update the accumulative variable to sum coverge more\n",
    "    coverage_acum += coverage_more\n",
    "\n",
    "    # Add a new colummn  into the dicctionary correspont to more n adatoms\n",
    "    fractional_ac_coverage['coverage_more'] = coverage_acum.copy()\n",
    "\n",
    "    # Created the data frame \n",
    "    fractional_ac_coverage_set = pd.DataFrame(fractional_ac_coverage)\n",
    "\n",
    "    #Save data frame \n",
    "    fractional_ac_coverage_set.to_csv(f'/home/yor/Thesis/prueba/fractional_coverage_saved.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a1f3f",
   "metadata": {},
   "source": [
    "## ADD THE PLOTING & GIF ANIMATION \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6dbbca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities(\n",
    "                    n_adatoms,\n",
    "                    E_bind, \n",
    "                    hexagonal,\n",
    "                    rhombile, \n",
    "                    triangular,\n",
    "                    C_nPh6,\n",
    "                    T_max,\n",
    "                    T_min,\n",
    "                    n_sites): \n",
    "    \"\"\"\n",
    "    This function calculates the coverage on the surface when an adatom is inserted.\n",
    "\n",
    "    Inputs -------->\n",
    "    \n",
    "            n_adatoms  -- number of adatoms\n",
    "            C_Ph6      -- concentration of gas \n",
    "            T_max      -- maximum temperature\n",
    "            T_min      -- minimum temperature\n",
    "            n_sites    -- dimension of unit cell (ex. 18x24 = 432)\n",
    "            isolated   -- energy of isolated structure (It is zero by definition)\n",
    "            hexagonal  -- energy of adsorption of hexagonal structure\n",
    "            rhombile   -- energy adsorption of rhombile structure \n",
    "            triangular -- energy adsorption of triangular structure \n",
    "\n",
    "    Outputs -------->\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    n_E_bind = -float(E_bind)\n",
    "    \n",
    "    Temperature = np.linspace(T_min, T_max, T_max-T_min+1)\n",
    "\n",
    "    kb_T = Temperature*kB  # Energy [eV] equivalent to 100ºC , 25.3\n",
    "    \n",
    "    # Define the energy of isolated surface\n",
    "    isolated = 0\n",
    "    \n",
    "    # Calculate theta_Auad for array Temperature\n",
    "    theta_Auad = np.exp(n_E_bind / (kB * Temperature)) / (1 + np.exp(n_E_bind / (kB * Temperature)))\n",
    "\n",
    "    # Define a dicctionary initial with the columna Temperature to save probabilities\n",
    "    data = {'Temperatura': Temperature}\n",
    "\n",
    "    # Define a dicctionary initia to save values of probabilities*coverage\n",
    "    data_pxc = {'Temperatura': Temperature}\n",
    "\n",
    "    # Define the Absorption energy &  Kinetics Adsortion\n",
    "    K_ads = np.exp((4.311064999999871)/kb_T) \n",
    "    \n",
    "    \n",
    "    \n",
    "    ######## Calculations for No adatoms ######\n",
    "    \n",
    "    # Initialization of Probability with no adatom (adatom 0) \n",
    "    P_Nad_0 = (1 - theta_Auad) ** n_sites\n",
    "\n",
    "    # Add the first column to diccitonary of probabilities 'data' which is adatom 0\n",
    "    data['P_Nad_0'] = P_Nad_0\n",
    "\n",
    "    #  Arrhenius relation of kinetics \n",
    "    K_Ph6_0  = np.exp( (isolated)   /(kB * Temperature))        # Isolated molecule\n",
    "    K_3Ph6_0 = np.exp(-(hexagonal[0] ) /(kB * Temperature))     # Hexagonal\n",
    "    K_6Ph6_0 = np.exp(-(rhombile[0]  )   /(kB * Temperature))   # Rhombile\n",
    "    K_9Ph6_0 = np.exp(-(triangular[0]) /(kB * Temperature))     # Trinagular\n",
    "    \n",
    "    # Calculate Thetha for 0 adatoms\n",
    "    theta_clean_0 = 1 /(1 +   C_nPh6 * K_ads * (1 + K_3Ph6_0 + K_6Ph6_0 + K_9Ph6_0 ))\n",
    "\n",
    "\n",
    "    #Calculate the coverage of each structure in the surface  \n",
    "    theta_Ph6_0  = theta_clean_0 * C_nPh6   *  K_ads\n",
    "    theta_3Ph6_0 = theta_Ph6_0   * K_3Ph6_0\n",
    "    theta_6Ph6_0 = theta_Ph6_0   * K_6Ph6_0\n",
    "    theta_9Ph6_0 = theta_Ph6_0   * K_9Ph6_0\n",
    "    \n",
    "    # Define a dicctionary to save the probabilities*coverage of non adatoms juntionsç\n",
    "    \n",
    "    data_0 = {\n",
    "        \"Temperatur [K]\": Temperature ,\n",
    "        f\"theta_3Ph6\":     P_Nad_0  *  theta_3Ph6_0,\n",
    "        f\"theta_6Ph6\":     P_Nad_0  *  theta_6Ph6_0,\n",
    "        f\"theta_9Ph6\":     P_Nad_0  *  theta_9Ph6_0,\n",
    "        f\"theta_clean\":    P_Nad_0  *  theta_clean_0,\n",
    "        f\"theta_isolated\": P_Nad_0  *  theta_Ph6_0\n",
    "    }\n",
    "\n",
    "\n",
    "    # Create the data frame \n",
    "    probability_0 = pd.DataFrame(data_0)\n",
    "    \n",
    "    #Save data frame of coverage with non adatoms\n",
    "    probability_0.to_csv(f'/home/yor/Thesis/prueba/coverage_adatom_0_{E_bind}.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "\n",
    "    # fractional coverage which the sum of all networks structure\n",
    "    coverage_0 = probability_0['theta_3Ph6'] + probability_0['theta_6Ph6'] + probability_0['theta_9Ph6'] + probability_0['theta_clean'] + probability_0['theta_isolated']\n",
    "\n",
    "    ########### Finish calculations with no adatoms   ##############\n",
    "    \n",
    "    ###### Initializations of calculations of coverages from 1 to n adatoms  #######\n",
    "    \n",
    "    \n",
    "    # Define the initialization variable with coverage 0 \n",
    "    coverage_acum = coverage_0.copy()  # sum acummulative into the for loop\n",
    "    coverage_acum_2 = coverage_0.copy()  # sum acummulative into the for loop\n",
    "    # Define a dicctionary for fractional coverage acummulative \n",
    "    fractional_ac_coverage = {'Temperatura': Temperature,\n",
    "                          'coverage_0':  coverage_0}\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Plotting \n",
    "    # Configuración estética sin cuadrícula de fondo y con bordes de ticks\n",
    "    sns.set_style(\"ticks\")  \n",
    "    # Forzar uso de Times New Roman\n",
    "    plt.rcParams['font.family'] = 'serif'  # Usa 'serif' como alternativa en caso de que Times New Roman no esté disponible\n",
    "    plt.rcParams['font.serif'] = 'Times New Roman'  # Esto forzará a usar Times New Roman si está instalado\n",
    "    plt.rcParams['font.size'] = 12  # Tamaño de fuente 12\n",
    "    # Graficar las líneas\n",
    "    plt.plot(Temperature, coverage_0, color='black', linewidth=0.3)\n",
    "    # Rellenar el área entre la curva más baja y el eje inferior (y=0)\n",
    "    plt.fill_between(Temperature, 0, coverage_0, color='cyan', alpha=0.8, label='No adatom')\n",
    "    \n",
    "    \n",
    "    # Loop for to adding values into dicctionaries \n",
    "    for i in range(1, n_adatoms + 1):\n",
    "        \n",
    "        # Calculate using a recursive functions the probabilities of n adatoms\n",
    "        P_Nad_i = (1 - sum(data['P_Nad_' + str(j)] for j in range(i))) * (1 - theta_Auad) ** (n_sites - i)\n",
    "        \n",
    "        # Save the  values of probabilities into a dicctionary\n",
    "        data['P_Nad_' + str(i)] = P_Nad_i\n",
    "\n",
    "        #Arrhenius relation according the energies i of the array defined\n",
    "    \n",
    "        K_Ph6  = np.exp( (isolated)   /(kB * Temperature))     # Isolated molecule\n",
    "        K_3Ph6 = np.exp(-(hexagonal[i] ) /(kB * Temperature))     # Hexagonal\n",
    "        K_6Ph6 = np.exp(-(rhombile[i]  )   /(kB * Temperature))  # Rhombile\n",
    "        K_9Ph6 = np.exp(-(triangular[i]) /(kB * Temperature))  # Trinagular\n",
    "\n",
    "\n",
    "        # Calculate Thetha \n",
    "        theta_clean = 1 /(1 +   C_nPh6 * K_ads * (1 + K_3Ph6 + K_6Ph6 + K_9Ph6 ))\n",
    "\n",
    "\n",
    "        # Calculate the coverage of each structure in the surface \n",
    "        theta_Ph6  = theta_clean * C_nPh6   *  K_ads\n",
    "        theta_3Ph6 = theta_Ph6   * K_3Ph6\n",
    "        theta_6Ph6 = theta_Ph6   * K_6Ph6\n",
    "        theta_9Ph6 = theta_Ph6   * K_9Ph6\n",
    "\n",
    "        # Define a dicctionary to save the values of probabliites* coverage of n adatoms\n",
    "        data_pxc = {\n",
    "            \"Temperatur [K]\": Temperature ,\n",
    "            f\"theta_3Ph6\":     P_Nad_i  *  theta_3Ph6,\n",
    "            f\"theta_6Ph6\":     P_Nad_i  *  theta_6Ph6,\n",
    "            f\"theta_9Ph6\":     P_Nad_i  *  theta_9Ph6,\n",
    "            f\"theta_clean\":    P_Nad_i  *  theta_clean,\n",
    "            f\"theta_isolated\": P_Nad_i  *  theta_Ph6}\n",
    "\n",
    "\n",
    "        # Created the data frame of the coverage*probabilities of n adatoms\n",
    "        probability = pd.DataFrame(data_pxc)\n",
    "\n",
    "        #Save data frame \n",
    "        probability.to_csv(f'/home/yor/Thesis/prueba/coverage_{i}_adatom__{E_bind}.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "        # Define the coverage of i adatoms which is the sum total of the networks structural\n",
    "        coverage = probability['theta_3Ph6'] + probability['theta_6Ph6'] + probability['theta_9Ph6'] + probability['theta_clean'] + probability['theta_isolated']\n",
    "\n",
    "        # Sumar cobertura actual a la acumulada\n",
    "        coverage_acum += coverage.copy()\n",
    "        \n",
    "        # Sum accumalative of n adatoms coverage*probabilities\n",
    "        fractional_ac_coverage['coverage_' + str(i)] = coverage_acum.copy()\n",
    "        \n",
    "        # Graficar las líneas\n",
    "        plt.plot(Temperature, coverage_acum.copy(), color='black', linewidth=0.3)\n",
    "        \n",
    "        # Rellenar el área entre las curvas con diferentes colores\n",
    "        plt.fill_between(Temperature,coverage_acum_2, coverage_acum.copy(), alpha=0.8, label=f'{i} adatom')\n",
    "        \n",
    "        coverage_acum_2+= coverage.copy()\n",
    "        \n",
    "    ###### Calculations the other posible structures which are unstable #######\n",
    "    # Calcular P_Nad_more which is the non defined strucutres \n",
    "    P_Nad_more = 1 - sum(data['P_Nad_' + str(j)] for j in range(n_adatoms + 1))\n",
    "    \n",
    "    # Save the values of P_Nad_more on dicctionary of probabilities*coverage\n",
    "    data['P_Nad_more'] = P_Nad_more\n",
    "\n",
    "    # Define a new dictionary of more n adatoms\n",
    "    \n",
    "    data_pxc_more = {\n",
    "        \"Temperatur [K]\": Temperature ,\n",
    "        f\"theta_3Ph6\":     P_Nad_more  *  theta_3Ph6,\n",
    "        f\"theta_6Ph6\":     P_Nad_more  *  theta_6Ph6,\n",
    "        f\"theta_9Ph6\":     P_Nad_more  *  theta_9Ph6,\n",
    "        f\"theta_clean\":    P_Nad_more  *  theta_clean,\n",
    "        f\"theta_isolated\": P_Nad_more  *  theta_Ph6}\n",
    "\n",
    "\n",
    "\n",
    "    # Created the data frame \n",
    "    probability_more = pd.DataFrame(data_pxc_more)\n",
    "    \n",
    "    #Save data frame \n",
    "    probability_more.to_csv(f'/home/yor/Thesis/prueba/coverage_adatom_more_{E_bind}.dat', sep= \" \", index=False,header=False)\n",
    "    \n",
    "    # define a sum of all structure difined \n",
    "    coverage_more = probability_more['theta_3Ph6'] + probability_more['theta_6Ph6'] + probability_more['theta_9Ph6'] + probability_more['theta_clean'] + probability_more['theta_isolated']\n",
    "\n",
    "   # Convertir el diccionario en DataFrame\n",
    "    #df = pd.DataFrame(data)\n",
    "\n",
    "    # Guardar en archivo CSV_\n",
    "    #df.to_csv('/home/yor/Thesis/prueba/probabilities_set.csv', index=False, header=False)\n",
    "\n",
    "    # Update the accumulative variable to sum coverge more\n",
    "    coverage_acum += coverage_more\n",
    "    \n",
    "    plt.plot(Temperature, coverage_acum, color='black', linewidth=0.3)\n",
    "    plt.fill_between(Temperature, coverage_acum_2, 1 , color='black', alpha=0.8,  label='more adatom')\n",
    " \n",
    "    # Add a new colummn  into the dicctionary correspont to more n adatoms\n",
    "    fractional_ac_coverage['coverage_more'] = coverage_acum.copy()\n",
    "\n",
    "    # Created the data frame \n",
    "    fractional_ac_coverage_set = pd.DataFrame(fractional_ac_coverage)\n",
    "\n",
    "    #Save data frame \n",
    "    fractional_ac_coverage_set.to_csv(f'/home/yor/Thesis/prueba/fractional_coverage_saved_{E_bind}.dat', sep= \" \", index=False,header=False)\n",
    "\n",
    "# Ajustar límites para asegurar visibilidad completa\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlim(200, 700)\n",
    "\n",
    "    # Mejorar la leyenda\n",
    "    legend = plt.legend(frameon=True)\n",
    "    for text in legend.get_texts():\n",
    "        plt.setp(text, color='black')  # Color de texto en negro para mejor visibilidad\n",
    "    # Borde negro en la caja de leyenda\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_color('white')  # Color de fondo blanco\n",
    "    frame.set_edgecolor('black')  # Color del borde de la caja de leyenda\n",
    "\n",
    "    # Bordes negros en el gráfico\n",
    "    plt.gca().spines['top'].set_color('black')\n",
    "    plt.gca().spines['right'].set_color('black')\n",
    "    plt.gca().spines['bottom'].set_color('black')\n",
    "    plt.gca().spines['left'].set_color('black')\n",
    "    \n",
    "    \n",
    "    # Títulos y etiquetas de los ejes en Times New Roman\n",
    "    plt.title(rf'Coverage of Network Formation on Au (111) with E_bind = -{E_bind} [V]')\n",
    "    plt.xlabel('Temperatura [K]', fontsize=12, fontname='Times New Roman')\n",
    "    plt.ylabel('Fractional Coverage [u.a.]', fontsize=12, fontname='Times New Roman')\n",
    "\n",
    "    plt.savefig(f'/home/yor/Thesis/prueba/network_formation_{E_bind}.png', dpi=300, bbox_inches='tight')\n",
    "    # Mostrar gráfico\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e964892e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probabilities(n_adatoms,\n",
    "                    E_bind, \n",
    "                    hexagonal,\n",
    "                    rhombile, \n",
    "                    triangular,\n",
    "                    C_nPh6,\n",
    "                    T_max,\n",
    "                    T_min,\n",
    "                    n_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fac84d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.00', '0.01', '0.02', '0.03', '0.04', '0.05', '0.06', '0.07', '0.08', '0.09', '0.10', '0.11', '0.12', '0.13', '0.14', '0.15', '0.16', '0.17', '0.18', '0.19', '0.20', '0.21', '0.22', '0.23', '0.24', '0.25', '0.26', '0.27', '0.28', '0.29', '0.30', '0.31', '0.32', '0.33', '0.34', '0.35', '0.36', '0.37', '0.38', '0.39', '0.40', '0.41', '0.42', '0.43', '0.44', '0.45', '0.46', '0.47', '0.48', '0.49', '0.50', '0.51', '0.52', '0.53', '0.54', '0.55', '0.56', '0.57', '0.58', '0.59', '0.60', '0.61', '0.62', '0.63', '0.64', '0.65', '0.66', '0.67']\n"
     ]
    }
   ],
   "source": [
    "# Generar 68 valores entre 0.00 y -0.67\n",
    "energies = np.linspace(0.00, 0.67, 68)\n",
    "\n",
    "itera = range(0,len(energies),1)\n",
    "\n",
    "# Formatear cada valor a dos decimales usando una lista de comprensión\n",
    "energies_formatted = [f\"{energy:.2f}\" for energy in energies]\n",
    "print(energies_formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "763dbaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e_binding in energies_formatted:\n",
    "    probabilities(n_adatoms,\n",
    "                    e_binding, \n",
    "                    hexagonal,\n",
    "                    rhombile, \n",
    "                    triangular,\n",
    "                    C_nPh6,\n",
    "                    T_max,\n",
    "                    T_min,\n",
    "                    n_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd668f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF guardado como /home/yor/Thesis/prueba/animation_6_adatoms.gif\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Ruta a las imágenes\n",
    "images_in = glob.glob(\"/home/yor/Thesis/prueba/network_formation_****.png\")\n",
    "\n",
    "# Cargar las imágenes\n",
    "images = [Image.open(img) for img in sorted(images_in)]\n",
    "\n",
    "# Crear el GIF\n",
    "gif_image_out = f\"/home/yor/Thesis/prueba/animation_{n_adatoms}_adatoms.gif\"\n",
    "images[0].save(gif_image_out, save_all=True, append_images=images[1:], duration=400, loop=0)\n",
    "\n",
    "print(f\"GIF guardado como {gif_image_out}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf269d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e97f13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e2019c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1388763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f217a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589376af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d62a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ecb1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0cc9076",
   "metadata": {},
   "source": [
    "# VERIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0505b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import coverage_{i} dataframe \n",
    "coverage_0 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_0.dat', sep= \" \", header=None)\n",
    "coverage_1 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_1.dat', sep= \" \", header=None)\n",
    "coverage_2 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_2.dat', sep= \" \", header=None)\n",
    "coverage_3 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_3.dat', sep= \" \", header=None)\n",
    "coverage_4 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_4.dat', sep= \" \", header=None)\n",
    "coverage_5 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_5.dat', sep= \" \", header=None)\n",
    "coverage_6 = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_6.dat', sep= \" \", header=None)\n",
    "coverage_more = pd.read_csv('/home/yor/Thesis/prueba/coverage_adatom_more.dat', sep= \" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2933d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de DataFrames\n",
    "dataframes = [coverage_0, coverage_1, coverage_2, coverage_3,coverage_4, coverage_5 , coverage_6, coverage_more]\n",
    "\n",
    "# Excluir la primera fila y la primera columna de cada DataFrame\n",
    "excluded_dfs = [df.iloc[:, 1:] for df in dataframes]\n",
    "\n",
    "# Sumar todas las columnas de los DataFrames excluidos\n",
    "sum_columns_general = sum(df.sum(axis=1) for df in excluded_dfs)\n",
    "\n",
    "# Crear un nuevo DataFrame con la suma total\n",
    "result_df = pd.DataFrame(sum_columns_general, columns=['Total Sum'])\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(\"Suma total de todas las columnas (excluye la primera columna):\\n\", result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab33abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c6328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
